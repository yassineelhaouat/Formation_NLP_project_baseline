# üöÄ Baseline Projet Veille Automatique - NLP

**Syst√®me end-to-end de collecte, analyse et synth√®se d'articles techniques**

## üìã Contenu du Projet

```
baseline_project/
‚îú‚îÄ‚îÄ config.json                 # Configuration (sources, mod√®les, etc.)
‚îú‚îÄ‚îÄ main.py                     # Script orchestrateur principal
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ src/                        # Code source
‚îÇ   ‚îú‚îÄ‚îÄ news_collector.py       # Collecte articles
‚îÇ   ‚îú‚îÄ‚îÄ text_preprocessor.py    # Pr√©traitement NLP
‚îÇ   ‚îú‚îÄ‚îÄ news_classifier.py      # Classification
‚îÇ   ‚îî‚îÄ‚îÄ report_generator.py     # G√©n√©ration rapport
‚îÇ
‚îú‚îÄ‚îÄ data/                       # Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ articles_raw.jsonl      # Articles bruts (output)
‚îÇ   ‚îú‚îÄ‚îÄ articles_processed.jsonl# Articles trait√©s (output)
‚îÇ   ‚îú‚îÄ‚îÄ articles_classified.jsonl# Articles classifi√©s (output)
‚îÇ   ‚îî‚îÄ‚îÄ collection_errors.json  # Log d'erreurs (output)
‚îÇ
‚îú‚îÄ‚îÄ output/                     # R√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ veille_report.txt       # Rapport final (output)
‚îÇ
‚îî‚îÄ‚îÄ notebooks/                  # Jupyter notebooks (optionnel)
    ‚îî‚îÄ‚îÄ 01_exploratory_data_analysis.ipynb
```

## üéØ Qu'est-ce qu'un Baseline?

Ce projet est un **point de d√©part fonctionnel** que tu **dois √©tendre et am√©liorer**:

### ‚úÖ Ce qui est D√âJ√Ä IMPL√âMENT√â (Baseline)
- ‚úì Collecte HackerNews + RSS (sources partielles)
- ‚úì Normalisation basique (HTML, URLs, case)
- ‚úì Tokenization spaCy fran√ßais
- ‚úì Classification zero-shot (mod√®le pr√©-entra√Æn√©)
- ‚úì Sentiment analysis basique
- ‚úì D√©tection doublons (cosinus similarity)
- ‚úì G√©n√©ration rapport structur√©e

### üéì Ce que VOUS devez AM√âLIORER (Travail √âtudiant)

**Niveau 0 (Fondamental)** : Utiliser asis
```python
# "C'est bon, j'ai un syst√®me qui fonctionne"
```

**Niveau 1 ** : Ajouter sophistication
```python
# "Je vais am√©liorer la confiance du NER"
# "Je vais fine-tuner le classifier sur nos donn√©es"
# "Je vais impl√©menter semantic similarity pour duplicates"
#....
```

**Niveau 2 ** : Production-ready + innovations
```python
# "Je vais ajouter caching + async pour scalabilit√©"
# "Je vais impl√©menter custom NER avec spaCy"
# "Je vais cr√©er metrics d'√©valuation rigoureuses"
```

---

## üöÄ D√©marrage Rapide

###  Installation

```bash
# Cloner/t√©l√©charger le baseline
cd baseline_project

# Cr√©er virtualenv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer d√©pendances
pip install -r requirements.txt

# T√©l√©charger mod√®les spaCy fran√ßais
python -m spacy download fr_core_news_sm
```

###  Configuration

√âditer `config.json` selon tes besoins:
```json
{
  "collection": {
    "hacker_news": {
      "enabled": true,
      "num_pages": 2  // Changer nombre pages
    },
    "pycoders_rss": {
      "enabled": true
    }
  },
  "preprocessing": {
    "language": "fr",
    "remove_stopwords": true
  }
  // ...
}
```

### Ex√©cuter le Pipeline

```bash
# Mode simple
python main.py

# Mode avec logging d√©taill√©
python main.py 2>&1 | tee run.log

# Mode avec profiling
python -m cProfile -s cumtime main.py > profile.txt
```

### 4Ô∏è‚É£ Afficher R√©sultats

```bash
# Lire rapport g√©n√©r√©
cat output/veille_report.txt

# Analyser donn√©es
head -10 data/articles_raw.jsonl
head -10 data/articles_processed.jsonl
head -10 data/articles_classified.jsonl
```

---

## üìö Structure Code

### Chaque Module est Ind√©pendant

```python
# ‚úÖ Peux utiliser s√©par√©ment:

# 1. Juste collecte
from src.news_collector import NewsCollector
collector = NewsCollector(config)
articles = collector.collect_from_hacker_news()

# 2. Juste pr√©traitement
from src.text_preprocessor import TextPreprocessor
preprocessor = TextPreprocessor(config)
processed = preprocessor.process_batch(articles)

# 3. Juste classification
from src.news_classifier import NewsClassifier
classifier = NewsClassifier(config)
classified = classifier.classify_batch(articles)

# 4. Juste rapport
from src.report_generator import ReportGenerator
generator = ReportGenerator(config)
report = generator.generate(articles)
```

---

## üîç Explications Code

### Chaque module a des commentaires d√©taill√©s

```python
# src/news_collector.py
"""
üì• Module Collecte d'Articles

DESIGN DECISIONS document√©s :
1. Pourquoi BeautifulSoup? Car structure HTML stable
2. Pourquoi 2 pages HackerNews? Assez pour d√©mo
3. Gestion timeouts : Retry logic avec delays

√Ä AM√âLIORER :
- Ajouter YouTube API (actuellement TODO)
- Ajouter GitHub API (trending repos)
- Impl√©menter caching (ne pas re-scraper m√™me URLs)
"""
```

---

## üìä Format Donn√©es

### Tout est JSON (facile √† analyser)

```jsonl
# data/articles_raw.jsonl
{"title": "BERT Tutorial", "url": "...", "content": "...", "source": "HackerNews", ...}
{"title": "Fine-tuning...", "url": "...", "content": "...", "source": "RSS", ...}

# data/articles_processed.jsonl
{...plus: "tokens": [...], "normalized_content": "...", "token_loss_pct": 45.2}

# data/articles_classified.jsonl
{...plus: "topic_prediction": "Advanced", "sentiment_label": "Positif", "is_duplicate": false}
```

---

## ‚úÖ Checklist pour √âtudiants

### √Ä compl√©ter/am√©liorer:

- [ ] **Collecte**
  - [ ] Impl√©menter YouTube scraper (au lieu de stub)
  - [ ] Ajouter GitHub API
  - [ ] Ajouter Medium API
  - [ ] Impl√©menter retry + exponential backoff

- [ ] **Pr√©traitement**
  - [ ] Tester impact remove_accents: True vs False
  - [ ] Comparer spaCy vs NLTK sur timing
  - [ ] Analyser token_loss_pct (est-ce normal 45%?)
  - [ ] Ajouter stemming optionnel

- [ ] **Classification**
  - [ ] Fine-tuner sur 100+ articles annot√©s
  - [ ] √âvaluer P/R/F1 sur test set
  - [ ] Comparer mod√®les: distilbert vs roberta
  - [ ] Impl√©menter custom NER (technos sp√©cifiques)

- [ ] **Rapport**
  - [ ] Ajouter visualisations (wordcloud, charts)
  - [ ] Calculer trend analysis (topics semaine pr√©c√©dente vs actuelle)
  - [ ] Ajouter insights qualitatifs
  - [ ] Exporter aussi en JSON/Markdown

- [ ] **Optionnel (E4)**
  - [ ] Impl√©menter caching (SQLite/Redis)
  - [ ] Async processing pour speed
  - [ ] API FastAPI pour servir rapport
  - [ ] Dashboard web (Streamlit)
  - [ ] Notifications email/Slack

---

## üêõ Troubleshooting

### Erreur: "module 'spacy' has no attribute 'load'"
```bash
# Solution: T√©l√©charger le mod√®le
python -m spacy download fr_core_news_sm
```

### Erreur: "CUDA out of memory"
```python
# Dans config.json, changer:
"device": -1  # Forcer CPU au lieu de GPU
```

### Articles collect√©s = 0
```bash
# V√©rifier: HackerNews accessible?
curl https://news.ycombinator.com/

# Sinon: Activer juste RSS dans config.json
```

### Classification lente
```python
# Solution 1: Utiliser mod√®le plus petit
"model_name": "distilbert-base-multilingual-uncased"  # Plus rapide

# Solution 2: Batch processing avec huggingface
# (d√©j√† impl√©ment√© dans le code)
```

---

## üìñ Ressources Documentation

### Modules Utilis√©s (official docs)

- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [spaCy](https://spacy.io/)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [scikit-learn](https://scikit-learn.org/)

### Papers Acad√©miques

- Vaswani et al. (2017) - "Attention is All You Need"
- Devlin et al. (2018) - "BERT: Pre-training..."

---

## üéØ Conseils √âtudiant

### 1. Comprendre CHAQUE module
```python
# Ne pas copier-coller aveugl√©ment!
# Lire code de NewsCollector:
# - Pourquoi BeautifulSoup et pas Selenium?
# - Pourquoi ce regex pour URLs?
# - O√π est la gestion d'erreurs?
```

### 2. Ajouter vos propres am√©liorations
```python
# Ne pas √©tendre, REMPLACER:
# "Je vais faire un meilleur NER"
# "Je vais impl√©menter semantic similarity"
# NOT: "J'ai juste enlev√© un print() du code"
```

### 3. Justifier chaque d√©cision
```python
# Dans votre pr√©sentation:
# "Nous avons choisi spaCy car X, Y, Z"
# "Trade-off: A vs B, nous choisissons A car..."
# "Limitation connue: C, am√©lioration future: D"
```

### 4. √âvaluer rigoureusement
```python
# Toujours calculer metrics:
# - Accuracy globale
# - Precision/Recall/F1 par classe
# - Confusion matrix
# - Analyse erreurs qualitative
```

---

## üí° Id√©es d'Extensions

**Easy (+5 pts)**
- Ajouter visualisations (wordcloud, bar charts)
- Impl√©menter caching de URLs scrap√©es
- Ajouter plus sources RSS

**Moyen (+10 pts)**
- Fine-tuning classifier sur 100 articles annot√©s
- Impl√©mentation custom NER (frameworks sp√©cifiques)
- Dashboard web (Streamlit)

**Difficile (+15 pts)**
- Production deployment (FastAPI API + Docker)
- Async processing (asyncio, concurrent.futures)
- Machine Learning pipeline (MLflow)
- Benchmark multiples mod√®les

---

## üìù Fonctionnement du Rapport

Le rapport g√©n√©r√© contient:

```
üì∞ VEILLE AUTOMATIQUE : NLP & Python
================================================

üìä R√âSUM√â EX√âCUTIF
  Articles collect√©s: 50
  Articles uniques: 45 (d√©dupli rate: 10%)

üî• TRENDING TOPICS (Sujets du moment)
  1. Fine-tuning LLMs (12 articles)
  2. RAG Systems (8 articles)
  3. French Models (5 articles)

‚ú® ARTICLES √Ä NE PAS MANQUER
  1. "Complete Guide to LoRA"
     Niveau: Advanced | Confiance: 0.95
  
  2. "Evaluating RAG Systems"
     Niveau: Intermediate | Confiance: 0.88

üìä ANALYSE TH√âMATIQUE
  Top Keywords:
    transformer (45 mentions)
    llm (38 mentions)
    fine-tuning (32 mentions)

üòä ANALYSE SENTIMENTS
  Positif: 55% (enthousiasme, innovations)
  Critique: 25% (limitations, co√ªts)
  Neutre: 20% (annonces)
```

---

## üéì Bon Travail!

Ce baseline est un **point de d√©part**, pas un produit fini.

**L'objectif n'est PAS** : "Faire tourner le code"

**L'objectif EST** : "Comprendre chaque ligne + am√©liorer + justifier"

Good luck! üöÄ
