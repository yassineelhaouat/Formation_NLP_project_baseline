# üöÄ Rapport Projet Veille Automatique NLP

**Syst√®me de classification automatique d'articles techniques**

---

## üìã Sommaire

1. [Pr√©sentation du Baseline](#1-pr√©sentation-du-baseline)
2. [Probl√®mes Identifi√©s](#2-probl√®mes-identifi√©s)
3. [Am√©liorations Apport√©es](#3-am√©liorations-apport√©es)
4. [R√©sultats & √âvaluation](#4-r√©sultats--√©valuation)
5. [Analyse des Erreurs](#5-analyse-des-erreurs)
6. [Conclusion & Perspectives](#6-conclusion--perspectives)

---

## 1. Pr√©sentation du Baseline

### üéØ Objectif du Syst√®me
Cr√©er un pipeline automatique de veille technologique :
- **Collecter** des articles de sources multiples
- **Pr√©traiter** le texte avec des techniques NLP
- **Classifier** par niveau de difficult√© (Beginner / Intermediate / Advanced)
- **G√©n√©rer** un rapport de synth√®se

### üì¶ Composants Fournis

| Module | Fonction | Technologies |
|--------|----------|--------------|
| `news_collector.py` | Scraping d'articles | BeautifulSoup, requests |
| `text_preprocessor.py` | Nettoyage NLP | spaCy, regex |
| `news_classifier.py` | Classification zero-shot | Transformers, sklearn |
| `report_generator.py` 

### üîß Pipeline Original
```
HackerNews ‚Üí Pr√©traitement spaCy ‚Üí Zero-shot Classification ‚Üí Rapport .txt
```

---

## 2. Probl√®mes Identifi√©s

### ‚ùå Probl√®me de Performance : 34% Accuracy

Apr√®s correction du mod√®le, le zero-shot classifier atteignait seulement **34.2% d'accuracy**.

**Analyse du biais** :
- Le mod√®le pr√©disait majoritairement **"Advanced"**
- Mauvaise g√©n√©ralisation sur nos cat√©gories sp√©cifiques
- Zero-shot non adapt√© √† notre domaine pr√©cis

### ‚ùå Probl√®me de Donn√©es : Source Unique

- Baseline = uniquement HackerNews
- Articles courts (titres + peu de contenu)

---

## 3. Am√©liorations Apport√©es

### ‚úÖ A) Enrichissement des Sources

**Action** : Ajout de TowardsDataScience comme 2√®me source

```python
# Dans config.json
"towards_data_science": {
    "enabled": true,
    "base_url": "https://towardsdatascience.com",
}
```

**R√©sultat** :
| M√©trique | Baseline | Am√©lior√© |
|----------|----------|----------|
| Sources | 1 | 2 |
| Articles | ~60 | 210 |
| Contenu | Titres seuls | Contenu complet |

---

### ‚úÖ B) Cr√©ation du Dataset Annot√©

**Action** : Annotation manuelle de 80+ articles

**Fichier cr√©√©** : `data/ground_truth_annotations.json`

**Crit√®res d'annotation d√©finis** :

| Label | Crit√®res |
|-------|----------|
| **Beginner** | Introduction aux concepts, guides de d√©marrage, tutoriels pour d√©butants, actualit√©s accessibles |
| **Intermediate** | N√©cessite des connaissances techniques, complexit√© mod√©r√©e, applications pratiques, utilisation d'outils |
| **Advanced** | Contenu technique profond, syst√®mes de production, papers de recherche, expertise requise |

**Distribution des annotations** :
```
Beginner:     72 articles (36%)
Intermediate: 80 articles (40%)
Advanced:     50 articles (24%)
```

---

### ‚úÖ C) Fine-tuning du Classifier

**Action** : Entra√Ænement supervis√© sur nos annotations

**Mod√®le choisi** : `distilbert-base-uncased`
- Plus l√©ger que BERT complet
- Adapt√© aux ressources limit√©es (CPU)
- Bon compromis performance/vitesse


**Gestion du d√©s√©quilibre** :

Impl√©mentation d'un `WeightedTrainer` personnalis√© :
```python
class WeightedTrainer(Trainer):
    def compute_loss(self, model, inputs, ...):
        # Cross-entropy pond√©r√©e par classe
        loss_fct = nn.CrossEntropyLoss(weight=class_weights)
        return loss_fct(logits, labels)
```

**Poids calcul√©s** :
- Beginner: 0.93
- Intermediate: 0.84
- Advanced: 1.34

---

### ‚úÖ D) Notebooks d'√âvaluation

**Cr√©√©s** :
1. `01_exploratory_data_analysis.ipynb` - Analyse exploratoire des donn√©es
2. `02_evaluation_benchmarks.ipynb` - M√©triques et comparaisons
3. `03_fine_tuning.ipynb` - Pipeline complet de fine-tuning

**Contenu** :
- Distribution des articles par source
- Distribution des labels
- Longueur des articles
- Matrices de confusion
- M√©triques d√©taill√©es

---

## 4. R√©sultats & √âvaluation

### üìä Comparaison Baseline vs Fine-tuned

| M√©trique | Baseline (Zero-shot) | Fine-tuned |
|----------|---------------------|------------|
| **Accuracy** | 34.2% | **58.3%** |
| **Am√©lioration** | - | **+24.1** |

### üìà M√©triques D√©taill√©es (Fine-tuned)

```
              precision    recall  f1-score   support

Beginner       0.67        0.50      0.57        4
Intermediate   0.50        0.33      0.40        3
Advanced       0.56        0.83      0.67        6

accuracy                             0.58       13
macro avg      0.58        0.56      0.55       13
weighted avg   0.58        0.58      0.56       13
```

### üéØ Matrice de Confusion

**Baseline (Zero-shot)** :
```
              Predicted
              Beg   Int   Adv
Actual Beg  [  5     4    17  ]  ‚Üí Biais vers Advanced
       Int  [  7     4    21  ]  ‚Üí Biais vers Advanced  
       Adv  [  1     0    17  ]
```

**Fine-tuned** :
```
              Predicted
              Beg   Int   Adv
Actual Beg  [  2     1     1  ]  ‚Üí Meilleure distribution
       Int  [  1     1     1  ]  
       Adv  [  0     1     5  ]  ‚Üí Bon recall Advanced
```

---

## 5. Analyse des Erreurs

### üîç Types d'Erreurs Identifi√©es

**1. Confusion Beginner ‚Üî Intermediate**
- Articles d'introduction avec termes techniques
- Exemple : "Introduction to Docker" ‚Üí Class√© Intermediate

**2. Articles Courts**
- Peu de contexte pour la classification
- Titres seuls insuffisants

**3. Domaines Mixtes**
- Articles couvrant plusieurs niveaux
- Exemple : "From Zero to Hero in Machine Learning"

### üìâ Limites du Syst√®me

| Limite | Impact | Solution Potentielle |
|--------|--------|---------------------|
| Dataset petit (80 samples) | Overfitting | Annoter plus d'articles |
| D√©s√©quilibre des classes | Biais pr√©dictions | Data augmentation |
| Articles courts | Manque contexte | Fetch contenu complet |
| Source unique finale | Biais domaine | Ajouter plus de sources |

---