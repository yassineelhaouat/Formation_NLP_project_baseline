# ğŸ“Œ INSTRUCTIONS POUR Ã‰TUDIANTS - Projet Veille Automatique NLP

## âš ï¸ IMPORTANT Ã€ LIRE EN PREMIER

**Le baseline n'est PAS votre projet final.**

C'est un **point de dÃ©part fonctionnel** que vous **devez amÃ©liorer**.

---

## ğŸ¯ RÃ¨gle Fondamentale

### Baseline Seul = MAX 10/20

Si vous utilisez le baseline **sans aucune amÃ©lioration rÃ©elle** :
- Code fonctionne âœ“
- Rapport gÃ©nÃ©rÃ© âœ“
- **MAIS: Score maximum = 10/20 (Fondamental)**

**Pourquoi ?** Parce qu'utiliser du code qui marche n'est pas un apprentissage.

### Votre Objectif: AmÃ©liorer le Baseline

Pour obtenir **12/20 ou plus**, vous DEVEZ amÃ©liorer le systÃ¨me.

---

## ğŸ“‹ 3 Niveaux de CompÃ©tence

Choisissez le VÃ”TRE et suivez les exigences.

### NIVEAU E2 : "Je veux juste rÃ©ussir" (12/20)

**Effort minimal mais reconnu:**
```
Baseline + 1 amÃ©lioration superficielle
  âœ“ Code baseline fonctionne
  âœ“ Ajouter 1 source supplÃ©mentaire OU
  âœ“ Tweaks mineurs (seuils, paramÃ¨tres)
  âœ— Aucune amÃ©lioration algorithmique
  
  Temps estimÃ©: 3-4h additional
  Score: 16/20 (Fondamental)
  
  Exemples:
  - Ajouter un regex pour mieux nettoyer URLs
  - Changer le seuil de similaritÃ© (0.85 â†’ 0.80)
  - AmÃ©liorer les rapports visuellement
```

**Bon Ã  faire:**
```
"J'ajoute GitHub API pour collecter trending repos"
 â†’ C'est une vraie amÃ©lioration + collecte
 â†’ Utile pour le systÃ¨me
 â†’ Effort rÃ©Ã©l
```

**Pas bon Ã  faire:**
```
"J'ajoute des commentaires au code"
 â†’ C'est cosmÃ©tique, pas une amÃ©lioration
```

---

### NIVEAU E3 : "Je veux vraiment apprendre" (15/20)

**Apprentissage rÃ©el avec mesures:**
```
Baseline + amÃ©lioration SIGNIFICATIVE

OPTION A : Fine-tuning
  âœ“ Annoter 50+ articles pour dataset
  âœ“ Fine-tuner classifier (distilbert â†’ custom)
  âœ“ Montrer: Accuracy baseline 0.65 â†’ 0.82 (17 points gain!)
  âœ“ Metrics: Precision/Recall/F1 par classe
  âœ“ Confusion matrix
  Temps: 10-15h additional
  
  Exemple rÃ©sultat attendu:
  ```
  Baseline (zero-shot): Accuracy 65%
  After fine-tuning: Accuracy 82%
  
  Class        Precision  Recall  F1
  DÃ©butant     0.85       0.88    0.86
  Intermediate 0.80       0.78    0.79
  Advanced     0.81       0.80    0.80
  ```

OPTION B : Custom NER
  âœ“ CrÃ©er NER pour technos spÃ©cifiques
    (PyTorch, TensorFlow, FastAPI, etc.)
  âœ“ Annoter 50+ articles
  âœ“ Train spaCy custom model
  âœ“ Metrics: Precision/Recall/F1 > 0.80

  
  Exemple rÃ©sultat attendu:
  ```
  Custom NER extracts:
  "PyTorch implementation of BERT"
  â†’ Technology: [PyTorch, BERT]
  
  Metrics:
  Precision: 0.87
  Recall: 0.85
  F1: 0.86
  ```

OPTION C : Ajouter sources
  âœ“ GitHub API (trending repos)
  âœ“ Medium API (technical posts)
  âœ“ IntÃ©grer dans collecteur
  âœ“ Collecter 50+ articles par source
  âœ“ Analysis: "GitHub: 40% advanced vs HN: 20%"

Raison: "Code amÃ©liorÃ© + Ã©valuation rigoureuse"
```

**Bon Ã  faire:**
```
"Je fine-tuner le classifier.
 Baseline accuracy: 65%
 Mon version: 82%
 Voici les metrics:"
 â†’ Apprentissage rÃ©el
 â†’ Mesurable
 â†’ Justifiable
```

**Pas bon Ã  faire:**
```
"Je change la config.json (num_pages: 2 â†’ 3)"
 â†’ C'est pas une amÃ©lioration, c'est un paramÃ¨tre
```

---

### NIVEAU E4 : "Je veux Ãªtre excellent" (18/20)

**SystÃ¨me production-ready avec multiples amÃ©liorations:**
```
Baseline + MULTIPLES amÃ©liorations SUBSTANTIELLES

Minimum 2 de ces options:
  âœ“ Fine-tuning classifier (50+ exemples)
  âœ“ Custom NER implementation
  âœ“ Semantic similarity (embeddings)
  âœ“ Production features:
    - Caching layer (SQLite/Redis)
    - Async processing
    - FastAPI deployment
    - Docker containerization
  âœ“ 3+ sources supplÃ©mentaires
  âœ“ Visualisations avancÃ©es
    - Wordcloud
    - Timeline trends
    - Interactive dashboard

PLUS: Benchmarking rigoureux
  âœ“ Model comparison table
  âœ“ Latency analysis
  âœ“ Memory footprint
  âœ“ Scalability considerations

Temps: 20-25h additional
Score: 20/20 (Expert)
Raison: "Baseline transformed into production system"

Exemple rÃ©sultat attendu:
```
Model Comparison:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model           â”‚ Accuracy â”‚ Latencyâ”‚ Memory   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Baseline        â”‚ 65%      â”‚ 120ms  â”‚ 450MB    â”‚
â”‚ Fine-tuned      â”‚ 82%      â”‚ 150ms  â”‚ 500MB    â”‚
â”‚ Custom NER      â”‚ 85%      â”‚ 200ms  â”‚ 600MB    â”‚
â”‚ Deployment-opt  â”‚ 80%      â”‚  80ms  â”‚ 250MB    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Conclusion: Use fine-tuned for accuracy,
            deployment-opt for speed
```
```

**Bon Ã  faire:**
```
"Je vais faire du fine-tuning ET custom NER.
 Puis je compare avec baseline.
 Je vais aussi ajouter caching pour speed.
 Enfin je dÃ©ploie avec FastAPI."
 â†’ Multiple substantial improvements
 â†’ Production-ready
 â†’ Rigorous evaluation
```

**Pas bon Ã  faire:**
```
"J'ai changÃ© les couleurs du rapport"
 â†’ CosmÃ©tique, pas technique
```

---

## ğŸ“Š BarÃ¨me

### Checkpoint 1 : Collecte & PrÃ©traitement (10 pts)
Attendu: Montrez que vous avez compris data collection + preprocessing

```
Ã€ minimiser:
  - Code baseline compile? âœ“ (2 pts)
  - DonnÃ©es nettoyÃ©es? âœ“ (2 pts)

Ã€ maximiser:
  - AmÃ©lioration collecte?
  - Justification choix design?
  - Metrics qualitÃ© donnÃ©es?
  - E2: Code fonctionne â†’ 8/10
  - E3: + amÃ©lioration source â†’ 9/10
  - E4: + multiple sources + analysis â†’ 10/10
```

### Checkpoint 2 : Classification (20 pts)
Attendu: Fine-tuning OU custom NER, pas juste baseline

```
Ã€ minimizer:
  - Code compile? âœ“ (2 pts)
  - Baseline zero-shot works? âœ“ (2 pts)
  
Ã€ maximizer:
  - FINE-TUNING implÃ©mentÃ©? (4 pts)
    - Accuracy improvement mesurable
    - Metrics complets (P/R/F1)
  - ERROR ANALYSIS (3 pts)
    - 5+ erreurs analysÃ©es
    - Patterns identifiÃ©s
  
  - E2: Baseline seulement â†’ 10/20 (MAX)
  - E3: Baseline + fine-tuning â†’ 15-18/20
  - E4: Baseline + fine-tuning + custom NER â†’ 20/20
```

### Checkpoint 3 : Rapport (15 pts)
Attendu: Visualisations + insights, pas juste baseline

```
Ã€ minimizer:
  - Rapport texte âœ“ (7 pts)
  
Ã€ maximizer:
  - Visualisations personnalisÃ©es? (4 pts)
    - Wordcloud (technos)
    - Bar charts (sentiments)
    - Timeline (trends)
  - Insights nouveaux? (3 pts)
    - Pas juste ce que baseline dit
    - Analyse qualitative
  
  - E2: Baseline rapport â†’ 10/15
  - E3: + visualisations â†’ 13/15
  - E4: + insights originaux â†’ 15/15
```

### PrÃ©sentation (20 pts)
Attendu: Pouvoir JUSTIFIER vos choix et amÃ©liorations

```
Questions que vous aurez:

"Montrez-moi UNE amÃ©lioration clÃ©"
 â†’ PrÃªt? Oui: "J'ai fine-tunÃ© et..."
 â†’ Pas prÃªt? Non: "Euh... j'ai utilisÃ© le baseline..."
 
"Justifiez avec chiffres"
 â†’ PrÃªt: "Accuracy 65% â†’ 82%, +17 points"
 â†’ Pas prÃªt: "Euh... Ã§a marche"

"Qu'aurait fait le baseline lÃ ?"
 â†’ PrÃªt: "Baseline predirait 'Intermediate', mais c'est Advanced"
 â†’ Pas prÃªt: "Je sais pas..."

La prÃ©sentation teste si vous COMPRENEZ votre code.
Si vous juste copiez le baseline, vous Ã©chouez ces questions.
```

---

## ğŸš€ WORKFLOW RECOMMANDÃ‰

### 1 Collecte + Preprocessing

```
  - DÃ©compresser baseline_project.zip
  - Installer dependances: pip install -r requirements.txt
  - Run: python main.py
  - VÃ©rifier que Ã§a fonctionne âœ“
  - Lire src/news_collector.py
  - Lire src/text_preprocessor.py
  - Comprendre le flux donnÃ©es
 - DÃ©cider amÃ©lioration CP1:
    Option A (E2): Rien (baseline ok) â†’ 8/10
    Option B (E3): +1 source (GitHub API) â†’ 9/10
    Option C (E4): +2 sources â†’ 10/10
  - Montrer improvements
  - Documenter choix
```

### 2 Classification

```
  - Annoter 50+ articles pour fine-tuning
    (CrÃ©er CSV: text, label, confidence)
  - Lire src/news_classifier.py
  - ImplÃ©menter fine-tuning:
    ```python
    from transformers import Trainer, TrainingArguments
    trainer = Trainer(...)
    trainer.train()
    ```
  - Calculer metrics: Precision, Recall, F1
  - Confusion matrix
  - Montrer: Baseline 65% â†’ Fine-tuned 82%
  - Montrer metrics table
  - Montrer error analysis (5+ erreurs)
```

### 3 : Rapport + PrÃ©sentations

```
  - Ajouter visualisations (wordcloud, bar charts, ...)
  - Ã‰crire insights qualitatifs
  - Rapport final
  - Visualisations
  - Documentation complÃ¨te
 (PRESENTATIONS):
  - 5 min: dÃ©mo systÃ¨me live
  - 10 min: justifier amÃ©liorations
  - 5 min: Q&A technique
  
  Questions possibles:
  "Why fine-tuning?"
  "Show me your accuracy improvement"
  "What error patterns did you find?"
  "How would you improve further?"
```

---

## â“ FAQ

**Q: Est-ce que je peux juste utiliser le baseline?**
```
R: Oui, mais score MAX 16/20 (E2 seulement).
   Pour 18+ vous DEVEZ amÃ©liorer.
```

**Q: Qu'est-ce qui compte comme "amÃ©lioration"?**
```
R: AMÃ‰LIORATION (compte) :
  âœ“ Fine-tuning classifier
  âœ“ Custom NER
  âœ“ Ajouter sources
  âœ“ Semantic similarity
  âœ“ Production features (async, caching)
  
  PAS une amÃ©lioration (cosmÃ©tique) :
  âœ— Renommer variables
  âœ— Ajouter commentaires
  âœ— Changer couleurs rapport
  âœ— Reformater texte
```

**Q: Fine-tuning, c'est dur?**
```
R: Non, HuggingFace le rend facile:
   ```python
   from transformers import Trainer
   trainer = Trainer(model, args, train, eval)
   trainer.train()
   ```
   Cherchez "HuggingFace fine-tuning tutorial"





## âœ… FINAL CHECKLIST

Avant de commencer:

- [ ] J'ai compris que baseline â‰  projet final
- [ ] J'ai choisi mon niveau (E2, E3, E4)
- [ ] J'ai compris l'exigence d'amÃ©lioration
- [ ] Je peux justifier mes choix
- [ ] J'ai un plan (quoi amÃ©liorer)
- [ ] Je peux montrer metrics si E3/E4



## ğŸ“ Questions?

Si quelque chose n'est pas clair:
- Relire cette page
- Regarder les exemples dans les grilles d'Ã©valuation
- Demander Ã  Nastasia (votre instructrice)

Mais soyez sÃ»r d'une chose:
**Utiliser baseline sans amÃ©lioration = MAX 10/20**
**Pour 15+ : FAUT amÃ©liorer et justifier**

Bon courage! ğŸ“